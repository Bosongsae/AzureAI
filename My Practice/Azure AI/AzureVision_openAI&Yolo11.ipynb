{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import gradio as gr \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import platform, random, requests\n",
    "import io, base64, re, time \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image) :\n",
    "\n",
    "    model = YOLO(\"yolo11n.pt\")\n",
    "    results = model(image)\n",
    "    annotated_image = results[0].plot()\n",
    "\n",
    "    # boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    # masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    # keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    # probs = result.probs  # Probs object for classification outputs\n",
    "    # obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    # result.show()  # display to screen\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font():\n",
    "    font_size = 40   \n",
    "    if platform.system() == \"Windows\":\n",
    "        font = ImageFont.truetype(\"BCCARDB.ttf\", size=font_size)\n",
    "    else:\n",
    "        font = ImageFont.load_default(size=font_size)\n",
    "    \n",
    "    return font\n",
    "\n",
    "def random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_ENDPOINT = \"\"\n",
    "OPENAI_API_KEY = \"\"\n",
    "DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "\n",
    "SPEECH_ENDPOINT = \"\"\n",
    "SPEECH_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_basic(image_array) :\n",
    "    # header 정보 입력하기\n",
    "    headers = {\n",
    "        \"Content-Type\":\"application/json\",\n",
    "        \"api-key\": OPENAI_API_KEY\n",
    "    }\n",
    "\n",
    "    image = Image.fromarray(image_array)\n",
    "    buffered_io = io.BytesIO()\n",
    "    image.save(buffered_io, format='png')\n",
    "    base64_image = base64.b64encode(buffered_io.getvalue()).decode(\"utf-8\")\n",
    "    \n",
    "    messages = [{\"role\":\"system\",\"content\":[{\"type\":\"text\",\"text\":\"너는 사진속의 물체를 분석하는 전문가야, 분석결과는 한국어로 답변해줘\"}]}]\n",
    "\n",
    "    # user\n",
    "    # messages.append({\"role\": \"user\", \"content\": history[-1][\"content\"]})\n",
    "    # messages.append({\"role\": \"user\", \"content\": base64_image})\n",
    "    messages.append({\"role\":\"user\",\"content\":[{\"type\":\"text\", \"text\":\"Yolo 모델로 물체를 감지한 이미지야, 이 이미지 및 감지된 물체에 대해 자세히 설명해줘\"},{\"type\":\"image_url\",\"image_url\":{\"url\":f\"data:image/png;base64,{base64_image}\"}}]})\n",
    "    # body 정보 입력하기 \n",
    "    body = { \n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_tokens\": 1800,       \n",
    "    }         \n",
    "    \n",
    "    # POST \n",
    "    response = requests.post(OPENAI_ENDPOINT, headers=headers, json=body)    \n",
    "    if response.status_code == 200 :\n",
    "        response_json = response.json()\n",
    "        content = response_json['choices'][0]['message']['content']\n",
    "        ## citation_list = response_json['choices'][0]['message']['context']['citations']\n",
    "        ## content = re.sub(r'\\[doc(\\d+)\\]', r'[참조 \\1]', content)        \n",
    "        return content\n",
    "    else :\n",
    "        return \"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_tts(text, voice=\"ko-KR-SeoHyeonNeural\", file_name=\"response_audio.mp3\") :    \n",
    "    content_type = \"application/ssml+xml\"\n",
    "    output_format = \"audio-16khz-64kbitrate-mono-mp3\"\n",
    "    \n",
    "    body_raw = f\"\"\"<speak version='1.0' xml:lang='ko-KR'><voice name='{voice}'>{text}</voice></speak>\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\" : SPEECH_API_KEY,\n",
    "        \"Content-Type\" : content_type,\n",
    "        \"X-Microsoft-OutputFormat\" : output_format\n",
    "    }\n",
    "    response = requests.post(SPEECH_ENDPOINT, headers = headers, data=body_raw)\n",
    "\n",
    "    if response.status_code == 200 :\n",
    "        with open(file_name, 'wb') as audio_file :\n",
    "            audio_file.write(response.content)\n",
    "        return file_name\n",
    "    else :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text) :\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s!?]', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_tts(tts_text, voice_name) :\n",
    "    tts_re_text = clean_text(tts_text)\n",
    "    #request tts\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"response_audio_{timestamp}.mp3\"\n",
    "    audio_output = request_tts(tts_re_text, voice=voice_name, file_name=file_name)\n",
    "    return audio_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_chatbot(history, voice_name) :\n",
    "    \n",
    "    if history == 0 :\n",
    "        return None\n",
    "    elif history[-1]['role'] == \"user\" :\n",
    "        return None\n",
    "    else :\n",
    "        answer = history[-1][\"content\"]\n",
    "        if voice_name is None:\n",
    "            voice_name = \"ko-KR-SeoHyeonNeural\"  # Default voice\n",
    "        answer_audio = change_tts(answer, voice_name)        \n",
    "        return answer_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theme = gr.themes.Origin(\n",
    "    primary_hue=\"rose\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    "    text_size=gr.themes.Size(lg=\"17px\", md=\"15px\", sm=\"13px\", xl=\"24px\", xs=\"12px\", xxl=\"28px\", xxs=\"10px\"),\n",
    "    radius_size=\"lg\",\n",
    "    font=[gr.themes.GoogleFont('Gowun Batang'), gr.themes.GoogleFont('IBM Plex Sans KR '), gr.themes.GoogleFont('42dot Sans '), 'sans-serif'],\n",
    "    font_mono=[gr.themes.GoogleFont('Gowun Batang'), gr.themes.GoogleFont('IBM Plex Sans KR '), gr.themes.GoogleFont('42dot Sans '), 'monospace'],\n",
    ").set(\n",
    "    body_background_fill='*background_fill_secondary',\n",
    "    body_background_fill_dark='*neutral_800',    \n",
    "    body_text_color='*neutral_700',\n",
    "    body_text_size='*text_md',\n",
    "    embed_radius='*radius_md',\n",
    "    block_radius='*radius_md',\n",
    "    block_title_radius='*radius_md',\n",
    "    block_title_text_size='*text_md',\n",
    "    container_radius='*radius_md',\n",
    "    input_text_size='*text_sm',\n",
    "    button_large_text_size='*text_md',\n",
    "    form_gap_width='0px'     \n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo :\n",
    "    gr.Markdown(\"## Yolo와 OpenAI\", height=\"40px\")\n",
    "    gr.Markdown(\"### 웹캠으로 화면을 촬영후 원하는 화면을 캡쳐하여 분석하세요!\", height=\"30px\")\n",
    "    voice_list_female = [(\"서현\",\"ko-KR-SeoHyeonNeural\"), (\"선희\", \"ko-KR-SunHiNeural\"), (\"순복\",\"ko-KR-SoonBokNeural\"), (\"유진\", \"ko-KR-YuJinNeural\"), (\"지민\",\"ko-KR-JiMinNeural\")]\n",
    "    voice_list_male = [(\"국민\",\"ko-KR-GookMinNeural\"), (\"봉진\",\"ko-KR-BongJinNeural\"), (\"인준\", \"ko-KR-InJoonNeural\"), (\"현수\",\"ko-KR-HyunsuNeural\")]       \n",
    "    \n",
    "    with gr.Row() :        \n",
    "        webcam_input = gr.Image(label = \"실시간 화면\", sources=\"webcam\", width=480, height=270, mirror_webcam=False, streaming=True)\n",
    "        output_cam = gr.Image(label=\"검출 화면\", type='pil', interactive=False)\n",
    "        output_capture_image = gr.Image(label=\"캡처 화면\", interactive=False)\n",
    "\n",
    "    with gr.Row() :\n",
    "        captrue_btn = gr.Button(\"화면 캡쳐\", size=\"sm\")\n",
    "        send_gpt_btn = gr.Button(\"GPT로 분석하기\", size=\"sm\")\n",
    "\n",
    "    with gr.Column() :\n",
    "        gr.Markdown(\"### GPT의 분석결과\", height=\"30px\")\n",
    "        with gr.Row() :            \n",
    "            with gr.Column(scale=3) :\n",
    "                gpt = gr.Chatbot(label=\"분석 결과\", type=\"messages\", height=\"800px\")\n",
    "            with gr.Column(scale=1) :\n",
    "                gr.Markdown(\"### GPT목소리를 선택해 보세요\", height=\"30px\")\n",
    "                select_voice_gender = gr.Radio(label=\"GPT 성별 선택\", choices=[\"Female\", \"Male\"], value=\"Female\")\n",
    "                select_voice_name = gr.Dropdown(label=\"GPT 이름\", choices=voice_list_female, value=\"ko-KR-SeoHyeonNeural\")\n",
    "                chatbot_audio = gr.Audio(label=\"GPT Talk\", interactive=False, autoplay=True)  \n",
    "              \n",
    "    def stream_webcam(image) :\n",
    "        draw_image = detect_objects(image)\n",
    "        return draw_image\n",
    "    \n",
    "    def click_capture(image) :\n",
    "        return image \n",
    "    \n",
    "    def click_send_gpt(image, history) :\n",
    "        gpt_content = chatbot_basic(image)\n",
    "        history.append({\"role\": \"user\", \"content\": gr.Image(image)}) \n",
    "        history.append({\"role\": \"assistant\", \"content\": gpt_content})        \n",
    "        return history\n",
    "    \n",
    "    def gender_selects(select) :\n",
    "        if select == \"Female\" :\n",
    "            return gr.update(choices=voice_list_female, value=voice_list_female[0])                    \n",
    "        else :\n",
    "            return gr.update(choices=voice_list_male, value=voice_list_male[0])\n",
    "\n",
    "    webcam_input.stream(stream_webcam, inputs=[webcam_input], outputs=[output_cam])\n",
    "    captrue_btn.click(click_capture, inputs=[output_cam], outputs=[output_capture_image])\n",
    "    send_gpt_btn.click(click_send_gpt, inputs=[output_capture_image, gpt], outputs=[gpt])\n",
    "    # chatbot 답변 자동 tts\n",
    "    gpt.change(change_chatbot, inputs=[gpt, select_voice_name], outputs=[chatbot_audio]) \n",
    "    select_voice_gender.change(gender_selects, inputs=select_voice_gender, outputs=select_voice_name)\n",
    "    \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
